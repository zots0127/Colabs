{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zots0127/Colabs/blob/main/assets/hub/intelisl_midas_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "valuable-trust",
      "metadata": {
        "id": "valuable-trust"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# MiDaS\n",
        "\n",
        "*Author: Intel ISL*\n",
        "\n",
        "**MiDaS models for computing relative depth from a single image.**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/midas_samples.png\" alt=\"alt\" width=\"50%\"/>\n",
        "\n",
        "\n",
        "### Model Description\n",
        "\n",
        "[MiDaS](https://arxiv.org/abs/1907.01341) computes relative inverse depth from a single image. The repository provides multiple models that cover different use cases ranging from a small, high-speed model to a very large model that provide the highest accuracy. The models have been trained on 10 distinct datasets using\n",
        "multi-objective optimization to ensure high quality on a wide range of inputs.\n",
        "\n",
        "### Dependencies\n",
        "\n",
        "MiDaS depends on [timm](https://github.com/rwightman/pytorch-image-models). Install with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "pending-pioneer",
      "metadata": {
        "attributes": {
          "classes": [
            "shell"
          ],
          "id": ""
        },
        "id": "pending-pioneer",
        "outputId": "bc17bd58-0bf4-4581-b8ae-23371903a560",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.5-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.13.0+cu113)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->timm) (3.0.4)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.6.5\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "environmental-authentication",
      "metadata": {
        "id": "environmental-authentication"
      },
      "source": [
        "### Example Usage\n",
        "\n",
        "Download an image from the PyTorch homepage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "periodic-tamil",
      "metadata": {
        "id": "periodic-tamil",
        "outputId": "df3abe67-4a28-47d8-c38e-4e164380d080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('dog.jpg', <http.client.HTTPMessage at 0x7f6d81659bd0>)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
        "urllib.request.urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "printable-footage",
      "metadata": {
        "id": "printable-footage"
      },
      "source": [
        "Load a model (see [https://github.com/intel-isl/MiDaS/#Accuracy](https://github.com/intel-isl/MiDaS/#Accuracy) for an overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "practical-friend",
      "metadata": {
        "id": "practical-friend",
        "outputId": "2767c79d-1e67-43f7-b2ae-42ed1537980e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "ea315f68605b42959dabc01f9a48edf9",
            "fd69311f3c3a42fbaf58ca2fa63f697d",
            "ecad233af33b4788946e4128718061fb",
            "87e6840d59d846f2842dbc8897027303",
            "ab97abd12b744b96bdebdad928cb1436",
            "27762224342042ed96f81d40dfddc273",
            "b6af82cab518418487c17c3cafa1d1d3",
            "da79227c88e94cac9f99f7bdef1b9b84",
            "ced8736a14064e85a9836ae41fda5d43",
            "61bf671040414124be32dd6057cc582f",
            "543f48231bd144d7986609d544b9f664"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  \"You are about to download and run code from an untrusted repository. In a future release, this won't \"\n",
            "Downloading: \"https://github.com/intel-isl/MiDaS/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large-midas-2f21e586.pt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/1.28G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea315f68605b42959dabc01f9a48edf9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n",
        "#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n",
        "#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n",
        "\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "outside-boating",
      "metadata": {
        "id": "outside-boating"
      },
      "source": [
        "Move model to GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dressed-fifteen",
      "metadata": {
        "id": "dressed-fifteen",
        "outputId": "7aee965a-3a57-441b-fbc1-ccdcda1a7042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DPTDepthModel(\n",
              "  (pretrained): Module(\n",
              "    (model): VisionTransformer(\n",
              "      (patch_embed): PatchEmbed(\n",
              "        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
              "        (norm): Identity()\n",
              "      )\n",
              "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "      (blocks): Sequential(\n",
              "        (0): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (7): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (8): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (9): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (10): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (11): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (12): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (13): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (14): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (15): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (16): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (17): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (18): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (19): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (20): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (21): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (22): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (23): Block(\n",
              "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention(\n",
              "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): Mlp(\n",
              "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "            (act): GELU(approximate=none)\n",
              "            (drop1): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (drop2): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
              "      (fc_norm): Identity()\n",
              "      (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "    )\n",
              "    (act_postprocess1): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate=none)\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n",
              "    )\n",
              "    (act_postprocess2): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate=none)\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "    )\n",
              "    (act_postprocess3): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate=none)\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "    (act_postprocess4): Sequential(\n",
              "      (0): ProjectReadout(\n",
              "        (project): Sequential(\n",
              "          (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate=none)\n",
              "        )\n",
              "      )\n",
              "      (1): Transpose()\n",
              "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
              "      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (scratch): Module(\n",
              "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (refinenet1): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet2): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet3): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (refinenet4): FeatureFusionBlock_custom(\n",
              "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (resConfUnit1): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (resConfUnit2): ResidualConvUnit_custom(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (activation): ReLU()\n",
              "        (skip_add): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "      )\n",
              "      (skip_add): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (output_conv): Sequential(\n",
              "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): Interpolate()\n",
              "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (5): ReLU(inplace=True)\n",
              "      (6): Identity()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "midas.to(device)\n",
        "midas.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hindu-period",
      "metadata": {
        "id": "hindu-period"
      },
      "source": [
        "Load transforms to resize and normalize the image for large or small model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ignored-trailer",
      "metadata": {
        "id": "ignored-trailer",
        "outputId": "258d171e-c21e-49b9-8899-1000d591a51b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        }
      ],
      "source": [
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "\n",
        "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
        "    transform = midas_transforms.dpt_transform\n",
        "else:\n",
        "    transform = midas_transforms.small_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "existing-albania",
      "metadata": {
        "id": "existing-albania"
      },
      "source": [
        "Load image and apply transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f9tyqtgUpYXk"
      },
      "id": "f9tyqtgUpYXk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "lined-zoning",
      "metadata": {
        "id": "lined-zoning"
      },
      "outputs": [],
      "source": [
        "url, filename = (\"https://media.wired.com/photos/5d09594a62bcb0c9752779d9/1:1/w_1500,h_1500,c_limit/Transpo_G70_TA-518126.jpg\", \"dog.jpg\")\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "img = cv2.imread(filename)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "input_batch = transform(img).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noble-pastor",
      "metadata": {
        "id": "noble-pastor"
      },
      "source": [
        "Predict and resize to original resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "iraqi-emphasis",
      "metadata": {
        "id": "iraqi-emphasis"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    prediction = midas(input_batch)\n",
        "\n",
        "    prediction = torch.nn.functional.interpolate(\n",
        "        prediction.unsqueeze(1),\n",
        "        size=img.shape[:2],\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    ).squeeze()\n",
        "\n",
        "output = prediction.cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "different-cement",
      "metadata": {
        "id": "different-cement"
      },
      "source": [
        "Show result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "protected-antigua",
      "metadata": {
        "id": "protected-antigua",
        "outputId": "eccb1d1d-08b0-4770-8fa4-b2ab2b22fef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6d7b67e8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(output)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "received-directive",
      "metadata": {
        "id": "received-directive"
      },
      "source": [
        "### References\n",
        "[Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer](https://arxiv.org/abs/1907.01341)\n",
        "\n",
        "[Vision Transformers for Dense Prediction](https://arxiv.org/abs/2103.13413)\n",
        "\n",
        "Please cite our papers if you use our models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "conservative-annotation",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "conservative-annotation"
      },
      "outputs": [],
      "source": [
        "@article{Ranftl2020,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Katrin Lasinger and David Hafner and Konrad Schindler and Vladlen Koltun},\n",
        "\ttitle     = {Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer},\n",
        "\tjournal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},\n",
        "\tyear      = {2020},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "czech-houston",
      "metadata": {
        "attributes": {
          "classes": [
            "bibtex"
          ],
          "id": ""
        },
        "id": "czech-houston"
      },
      "outputs": [],
      "source": [
        "@article{Ranftl2021,\n",
        "\tauthor    = {Ren\\'{e} Ranftl and Alexey Bochkovskiy and Vladlen Koltun},\n",
        "\ttitle     = {Vision Transformers for Dense Prediction},\n",
        "\tjournal   = {ArXiv preprint},\n",
        "\tyear      = {2021},\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intelisl_midas_v2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea315f68605b42959dabc01f9a48edf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd69311f3c3a42fbaf58ca2fa63f697d",
              "IPY_MODEL_ecad233af33b4788946e4128718061fb",
              "IPY_MODEL_87e6840d59d846f2842dbc8897027303"
            ],
            "layout": "IPY_MODEL_ab97abd12b744b96bdebdad928cb1436"
          }
        },
        "fd69311f3c3a42fbaf58ca2fa63f697d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27762224342042ed96f81d40dfddc273",
            "placeholder": "​",
            "style": "IPY_MODEL_b6af82cab518418487c17c3cafa1d1d3",
            "value": "100%"
          }
        },
        "ecad233af33b4788946e4128718061fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da79227c88e94cac9f99f7bdef1b9b84",
            "max": 1376378527,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ced8736a14064e85a9836ae41fda5d43",
            "value": 1376378527
          }
        },
        "87e6840d59d846f2842dbc8897027303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61bf671040414124be32dd6057cc582f",
            "placeholder": "​",
            "style": "IPY_MODEL_543f48231bd144d7986609d544b9f664",
            "value": " 1.28G/1.28G [00:12&lt;00:00, 110MB/s]"
          }
        },
        "ab97abd12b744b96bdebdad928cb1436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27762224342042ed96f81d40dfddc273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6af82cab518418487c17c3cafa1d1d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da79227c88e94cac9f99f7bdef1b9b84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ced8736a14064e85a9836ae41fda5d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61bf671040414124be32dd6057cc582f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543f48231bd144d7986609d544b9f664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}